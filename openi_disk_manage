#!/usr/bin/env python3

# Imports ######################################################################

import json
import os
import stat
import sys
import re
import subprocess
import  shutil
import argparse
import socket
import pwd
import grp
import time
import datetime
import sys 

class Storcli():
    '''
    '''

    def __init__(self, args):

        # Vars ################################################################

        self.oio_disk = None
        self.mount_point = None
        self.naa = None
        self.clear_incident = True
        self.disk_failure = False
        self.replace = None
        self.wipe = None
        self.lock_file = None
        self.disk_uuid_old = None
        self.kern_log = "/var/log/kern.log"
        self.n_lines = 15
        self.get_device = False
        self.gridinit_cmd = ['DAILYMOTION-rawx', 'DAILYMOTION-rdir', 'DAILYMOTION-oio-blob-indexer']
        self.hostname = socket.gethostname()
        self.fstype = 'ext4'
        self.fstab = "/etc/fstab"
        self.now = datetime.datetime.now()
        self.date = datetime.datetime.strftime(self.now, '%m/%d/%Y')
        self.hour = time.strftime('%H:%M:%S')
        self.CV_OK_STATES = ["optimal"]
        self.VD_OK_STATES = ["optl"]
        self.PD_OK_STATES = ["onln", "ugood", "dhs", "ghs"]
        self.ip = socket.gethostbyname(socket.gethostname())
        self.RED   = "\033[1;31m"
        self.BLUE  = "\033[1;34m"
        self.CYAN  = "\033[1;36m"
        self.GREEN = "\033[0;32m"

        '''
        :disk = device : type => /cxx/exx/sxx
        :device = /dev/sdxx
        :oio_disk = diskxx ==> oiodisk
        :args.replace : when replacing faulty disk
        :args.wipe : wiping existing disk
        :args.oio : argument to set oio disk
        :args.device : argument to set disk 
        '''

        # Check if storcli binary exist and cluster is health ################

        self.cluster_health = self.check_cluster_status()
        self.storcli_binary = self.find_storcli_binary(storcli)
        if self.cluster_health == "NOK":
            self.error_exit("Err : OIO cluster is not healthy")
        elif not self.storcli_binary:
            self.error_exit("Err : C'ant found sotrcli binary")

        # Args ################################################################

        if args.wipe:#--wipe to wipe disk
            self.wipe = args.wipe
        if args.replace:#--replace to replace disk
            self.replace = args.replace
        if args.device:
            self.device = args.device#--device name : sdxx
        if args.oio:
            self.oiodisk = args.oio#--oio oiodisk name : diskxx
        if args.pdisk:
            self.pdisk = args.pdisk

        # Set vars if --replace + --oio + --pdisk  #####################################################
        '''
        use this when we want to change + wipe of pd when we cant found disk /dev/sdxx
        '''

        if args.replace and args.oio and args.pdisk:
            replace_unknow_disk = True
            self.disk = args.pdisk
            cmd = subprocess.getoutput(
                'storcli {} show J'.format(
                    disk,
             ))
            pd_status = json.loads(cmd)['Controllers'][0]['Command Status']['Status']
            if not pd_status == "Success":
                self.error_exit("Pdisk not valide : {}".format(self.disk))
            self.oio_disk = self.oiodisk
            self.device = self.disk_management(self.disk, self.kern_log, self.n_log)

        # Set vars if --wipe + --device  ################################################################
        '''
        use this when we want to change + wipe of pd of known disk /dev/sdxx
        '''

        if (args.wipe or args.replace) and args.device:
            if "/dev/" in self.device:
                stat.S_ISBLK(os.stat(self.device).st_mode)
            else:
                stat.S_ISBLK(os.stat("/dev/" + self.device).st_mode)
                self.device = "/dev/{}".format(self.device)

        # Set vars if --device + --wipe  ################################################################

            self.disk = self.check_vd_pd_health(self.device)
            self.mount_point = self.found_mount_p(self.device)
            self.oio_disk = self.found_mount_p(self.device)[33:]
            self.disk_uuid_old = self.get_uuid(self.device)
            
            if args.replace:
                if self.disk:
                    self.device = self.disk_management(self.disk, self.kern_log, self.n_log)
                else:
                    self.error_exit('Err : cant found PD encxxx slotxx of disk{}\nYou must use --oio and --pdisk options to avoid this error'.format(self.device))               

        # Set vars if --oio + --wipe  ################################################################
        #find the disk against the oiodisk given
        if (args.wipe or args.replace) and args.oio:
            if "disk" in self.oiodisk:
                self.oiodisk = self.oiodisk.split("disk")
            self.oio_disk = self.oiodisk
            self.get_device = True
            self.device = self.found_mount_p(self.get_device)
            with open("/etc/fstab") as fstab:
                for line in fstab:
                    if "disk{}".format(self.oiodisk) in line:
                        if  (line.split(" ")[1]).split("/")[6] == "disk{}".format(self.oiodisk):
                            uuid = (line.split("UUID=")[1]).split(" ")[0]
                            self.dev = subprocess.getoutput("blkid |grep \"{}\" |awk \'{{print $1}}\' |cut -d\':\' -f1".format(uuid))
                            if not self.device:
                                self.device = self.dev
                            else:
                                if self.device != self.dev:
                                    self.error_exit('Err : Wrong mount option')
                            if not self.device:
                                self.error_exit('Err : cant found disk mounted on disk{}'.format(self.oio_disk))
            if self.device:
                self.disk = self.check_vd_pd_health(self.device)
                self.get_device = False
                self.mount_point = self.found_mount_p(self.device)
                self.disk_uuid_old = self.get_uuid(self.device)
                if self.disk:if args.replace:
                if self.disk:
                    self.device = self.disk_management(self.disk, self.kern_log, self.n_log)
                else:
                    self.error_exit('Err : cant found PD encxxx slotxx of disk{}\nYou must use --oio and --pdisk options to avoid this error'.format(self.device))
                    
                #self.error_exit('Err : cant found PD encxxx slotxx of oiodisk{}\n You must use --oio and --pdisk options to avoid this error'.format(self.oiodisk)ld = self.get_uuid(self.device)
                #if not self.disk:
                 #   if not agrs.replace:
                                       

        self.lock_file = "/var/run/oio/disk{}".format(self.oio_disk)
        if os.path.isfile(self.lock_file):
            self.error_exit("Err : disk locked : {}".format(self.lock_file))
        else:
            os.mknod(self.lock_file)

        # Common process  ################################################################

        self.disk_state = subprocess.getoutput("gridinit_cmd status |grep \"rawx-{}\"".format(self.oio_disk)).split()[1]
        self.stop_start_oio_srv("stop", self.oio_disk, self.device, self.mount_point)
        self.rawx_status = self.check_rawx_status(self.oio_disk)
        if self.rawx_status not in  ("Broken", "Down"):
            self.error_exit('Err : cant wipe disk : rawx-{} is Up'.format(self.oio_disk))
        self.validation(self.disk, self.device, self.disk_uuid_old, self.oio_disk)
        self.wipe_disk(self.fstype, self.device, self.oio_disk, self.disk_uuid_old)
        self.stop_start_oio_srv("start", self.oio_disk, self.device, self.mount_point)
        time.sleep(10)
        self.rawx_status = self.check_rawx_status(self.oio_disk)
        print(self.rawx_status)
        if self.rawx_status in  ("Broken", "Down"):
            self.error_exit('Err : cant wipe disk : rawx-{} is Down'.format(self.oio_disk))
        #self.rebuild_oio(self.hostname, self.oio_disk, self.ip, self.date, self.hour, self.mount_point, self.device)

    # Functions  ################################################################

    def error_exit(self,message):
        '''
        Exit(3) when error detected
        '''
        print(self.RED + message)
        if self.lock_file:
            if os.path.isfile(self.lock_file):
                os.remove(self.lock_file)
        sys.exit(3)

    def printing_message(self, severity, msg):
        '''
        Format printed messages
        '''
        if severity == "Info":
            color = self.BLUE
        elif severity == "Notification":
            color = self.CYAN
        elif severity == "Error":
            color = self.RED
        elif severity == "Ok":
            color = self.GREEN
        else:
            self.error_exit("Uknown color")
        print(color + msg)


    def find_storcli_binary(self, program):
        path=os.getenv('PATH')
        for p in path.split(os.path.pathsep):
            p=os.path.join(p,pgm)
            if os.path.exists(p) and os.access(p,os.X_OK):
                return(p)

    def find_enc_slot(self, device):
        '''
        Find slot and enc of given device : using th diskhs.py script output
        '''
        disk_state = subprocess.getoutput(' diskhs.py --device {}'.format(device))
        r = re.search(r"/c0/e[0-9]+/s[0-9]+", disk_state)
        pdisk = r.group()
        if pdisk:
            return(pdisk)
        else:
            return None

    def check_vd_pd_health(self, device):
        '''
        CHeck health of given PD 
        '''
        disk = self.find_enc_slot(self.device)
        if disk:
            cmd = subprocess.getoutput(
                'storcli {} show J'.format(
                    disk,
             ))
            pd_status = json.loads(cmd)['Controllers'][0]['Response Data']['Drive Information'][0]['State']
            pd_global_status = json.loads(cmd)['Controllers'][0]['Command Status']['Status']
            if pd_status == "Onln" and pd_global_status == "Success":
                return(disk)
            else:
                 self.error_exit('Err : cant wipe faulty disk : must change it with --replace option')
        else:
            self.error_exit('Err : cant found disk')

    def check_cluster_status(self):
        '''
        Checking health of cluster
        '''
        self.oio_health_check = subprocess.getoutput("gridinit_cmd status")
        if "failed" in self.oio_health_check:
            cluster_health = "NOK"
        else:
            cluster_health = "OK"
        return(cluster_health)

    def found_mount_p(self, device):
        '''
        Find out the mount point from given /dev/disk
        '''
        cmd = "df -h | grep {}".format(device)
        mount_point = subprocess.getoutput(cmd).split(" ")[-1]
        if not  mount_point or (mount_point and self.get_device):
            Disk_uuid = self.get_uuid(device)
            if Disk_uuid:
                with open("/etc/fstab") as fstab:
                    for line in fstab:
                        if Disk_uuid in line:
                            if self.get_device:
                                mount_point = line.split(" ")[0]
                            else:
                                mount_point = line.split(" ")[1]
        return(mount_point)
    
    
    def detect_new_disk(self, kern_logn, n_lines):
        '''
        Get name of new disk
        '''
        proc = subprocess.Popen(['tail', '-n', str(n), f], stdout=subprocess.PIPE)
        lines = proc.stdout.readlines()
        re.findall('\[sd(.+?)\]', cmd)
        new_disk = subprocess.getoutput("tail -n {} {} |grep \"Attached SCSI disk\"".format(kern_logn, n_lines))
        new_disk = re.findall('\[sd(.+?)\]', new_disk)
        new_disk = "sd" + new_disk
        disk_exists = os.path.isfile('/dev/' + new_disk)
        if disk_exists:
            error_exit(self.RED + "Cant found the new disk")

    
    def disk_management(self, disk, kern_logn, n_lines):
        self.printing_message("Notification", "[Storcli] Enable LED on faulty disk : {}".format(disk))
        enable_led = self.cmd_execute("storcli {} start locate".format(disk))
        if not str("Succeeded") in str(enable_led):
            self.error_exit("Err : cant enable LED on {}".format(disk))
        self.printing_message("Notification", "[Storcli] Disable LED on faulty disk : {}".format(self.disk))
        user_choice("storcli {} stop locate".format(self.disk), "Notification", "[Storcli] Disable LED on faulty disk : {}".format(self.disk))
        self.printing_message("Notification", "[Storcli] Check status of changed disk : {}".format(disk))
        user_choice("test", "Notification", "Tape <yes> when finish changing disk")
        time.sleep(10)
        check_status = subprocess.getoutput("storcli {} show ".format(disk))
        if not "UGood" in check_status:
            self.error_exit(self.RED + "Disk {} was not correctly changed \n {}".format(disk, check_status))
        self.printing_message("Notification", "[Storcli] Create the corresponding RAID0 : {}".format(self.disk))
        if not str("Succeeded") in str(check_status):
            self.error_exit(self.RED + "Error when creating RAID0")
        p_disk = "/dev/" + detect_new_disk(kern_logn, n_lines)
        print(p_disk)

    def force_kill_process(self, oiodisk):
        ''' 
        Forcing kill OIO process
        '''
        check_process = subprocess.getoutput("ps faux |grep \"rdir-{}\" |grep openio | awk {{' print $2'}}".format(oiodisk))
        self.cmd_execute("kill -9 " + check_process)

    def stop_start_oio_srv(self, action, oiodisk, device, mount_p):
          '''
          Stop, start check oio services
          DAILYMOTION-rawx, DAILYMOTION-rdir, DAILYMOTION-oio-blob-indexer
          '''
          #Check if the disk was already locked by another rebuild
          check_rawx = subprocess.getoutput ("gridinit_cmd status |grep DAILYMOTION-rawx-{}".format(oiodisk))
          if action == "stop":
              self.printing_message("Info", "[OIO] : check if there is rebuild's-lock on disk-[{}]".format(oiodisk))
              Rebuild_in_progress = subprocess.getoutput("OIO_NS=DAILYMOTION openio volume admin show {}:62{}".format(self.ip, oiodisk))
              if "lock" in Rebuild_in_progress:
                  print(Rebuild_in_progress)
                  self.error_exit("Error", "Error: Rebuild in progress on {}:62{}".format(self.hostname, oiodisk))
              else:
                  print("Ok", "[Info]: No rebuild in progress on disk{} {}".format(oiodisk, Rebuild_in_progress))
              if "incident_date" in Rebuild_in_progress  and self.clear_incident :
                  print("Ok", "[OIO]: Clearing old incident lock on disk{} {}".format(oiodisk, Rebuild_in_progress))
                  self.cmd_execute("OIO_NS=DAILYMOTION openio volume admin clear {}:62{}".format(self.ip, oiodisk))
          for cmd in self.gridinit_cmd:
              self.printing_message("Info", "[OIO] : {} girid_init rawx, rdir and blob-indexer on disk{}".format(action, oiodisk))
              if action == "stop":
                  self.cmd_execute("gridinit_cmd {} {}-{}".format(action, cmd, oiodisk))
                  success = False
                  retries = 0
                  while True:
                      retries += 1
                      time.sleep(3)
                      self.force_kill_process(oiodisk)
                      wipe_output = subprocess.getoutput("umount -l /var/lib/oio/sds/DAILYMOTION/disk{}".format(oiodisk))
                      try:
                          check_mount = subprocess.getoutput("mount |grep  \"{}\"".format(device))
                          print(check_mount)
                          if  not check_mount:
                              success = True
                              break
                      except Exception as e:
                          print("Will retry : %s" % serr)
                      if retries >10:
                          self.printing_message("Error", "Locked volum\n" + check_mount)
                          self.error_exit("Err : Failed to unmout {} : Max-retries : {}".format(device, retries))
                          break
              elif action == "start":
                 self.cmd_execute("systemctl daemon-reload")
                 self.cmd_execute("mount -a")
                 check_mount = subprocess.getoutput("mount |grep {}".format(device))
                 if not check_mount:
                     self.error_exit("Error : Cant mount {}".format(device))
                 self.prepare_disk_env(oiodisk)
                 self.cmd_execute("gridinit_cmd {} {}-{}".format(action, cmd, oiodisk))
              else:
                  print(self.disk)
                  self.cmd_execute("mount -a")
                  if "Broken" in check_rawx:
                      self.error_exit(self.RED + "Error: OiO services related to disk {} is broken".format(disk))

    def validation(self, disk, device, uuid, oio_disk):
        '''
        Validation process before wiping disk
        '''
        elements = []
        n = locals()
        check_elements = ("disk", "device", "uuid", "oio_disk")
        for element in check_elements:
            if n[element]:
                elements.append(element + " : " + str(n[element]) + " : [Ok]")
            else:
                elements.append(element + " " + str(n[element]) + " : [Err]")
        if len(elements) > 0:
            print(elements)
            if any("Err" in s for s in elements):
                self.error_exit("error")
            else:
                self.user_choice("test", "Check information : if evrything is OK : tape <yes>")

    def get_uuid(self, device):
        '''
        Get uuid of given /dev/disk
        '''
        cmd = 'blkid {} | awk \'{{ print $3 }}\' |cut -d ""="" -f2 |sed \'s/^"\(.*\)".*/\\1/\''.format(device)
        Disk_uuid = subprocess.getoutput(cmd)
        return(Disk_uuid)

    def cmd_execute(self, command):
        '''
        Execute command and handle erros
        '''
        try:
            cmd = subprocess.Popen(command,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE)
            result = cmd.stdout.readlines()
            print(self.GREEN + "[Success]")
            return(result)
        except subprocess.CalledProcessError as exc:
            print(self.RED + "Status : FAIL", exc.returncode, exc.cmd)

    def check_rawx_status(self, oiodisk):
        '''
        Get status of rawx-x of a given disk
        Up, Broken, down
        '''
        rawx_status = subprocess.getoutput("gridinit_cmd status |grep \"\\<DAILYMOTION-rawx-{}\\>\"".format(self.oio_disk))
        if  "UP" in rawx_status:
            rawx_status = "Up"
        elif "DOWN" or "BROKEN" in rawx_status:
            rawx_status = "Down"
        elif "BROKEN" in rawx_status:
           rawx_status = "BROKEN"
        else:
            self.error_exit('Err : unknow state')
        return(rawx_status)

    def user_choice(self, cmd, msg):
        '''
        storcli start location on failed disk
        '''
        reply = ["yes"]
        user_choice = None
        while user_choice  not in reply:
            user_choice = input(msg + "\n")
        self.cmd_execute(cmd)


    def wipe_disk(self, fstype, device, oiodisk, uuid):
        if self.fstype == 'ext4':
            wipe_cmd = "mkfs.{} -F {} -L disk{}".format(fstype, device, oiodisk)
        else:
            error_exit(self.RED + "This script support only {} FS".format(self.fstype))
        success = False
        retries = 0
        self.printing_message("Ok", "[OIO] : Wiping {}] using {}".format(device, fstype))
        while True:
            retries += 1
            check_mount = subprocess.getoutput("mount |grep {}".format(device))
            if  check_mount:
                self.force_kill_process(oiodisk)
                self.cmd_execute("umount -l /var/lib/oio/sds/DAILYMOTION/disk{}".format(oiodisk))
            try:
                wipe_check = subprocess.getoutput(wipe_cmd)
                time.sleep(5)
                if self.get_uuid(self.device) != uuid:
                    success = True
                    break
            except Exception as e:
                print("Will retry : %s" % serr)
            if retries >10:
                self.error_exit("Err : Failed to wipe disk\n" + wipe_check)
                break
        cmd = "sed -i s/{}/{}/g {} && sed -i s/\"disk{} xfs \"/\"disk{} ext4\"/g {}".format(uuid, self.get_uuid(self.device), '/etc/fstab', oiodisk, oiodisk, '/etc/fstab')
        self.cmd_execute(cmd)

    def prepare_disk_env(self, oiodisk):
        '''
        Preparing the disk env, dirs and files
        '''
        oio_srv = ("rawx", "rdir")
        Base_dir = "/var/lib/oio/sds/DAILYMOTION/disk"
        uid = pwd.getpwnam("openio").pw_uid
        gid = grp.getgrnam("openio").gr_gid
        for srv in oio_srv:
            if not os.path.exists("{}{}/{}-{}".format(Base_dir, oiodisk, srv, oiodisk)):
                os.makedirs("{}{}/{}-{}".format(Base_dir, oiodisk, srv, oiodisk))
            os.chown("{}{}/{}-{}".format(Base_dir, oiodisk, srv, oiodisk), uid, gid)
            os.chown("{}{}/{}-{}".format(Base_dir, oiodisk,  srv, oiodisk), uid, gid)

    def launch_rebuild(self, y_msg, n_msg, oiodisk, cmd):
        '''
        Launching rebuild on changed disk
        '''
        reply = ["yes", "no"]
        user_choice = None
        while user_choice  not in reply:
            user_choice = input("Want to launch the rebuild now ?: yes/no \n")
        if user_choice == "yes":
            print(self.GREEN + y_msg)
            cmd = "screen -dmS rebuild-openio-disk-{} bash -c \"{}\"".format(oiodisk, cmd)
            self.cmd_execute(cmd)
            print("Watch then screen : [use : <screen -ls |grep \"rebuild-openio-disk-{}\"> to foundwanted screen".format(oiodisk, oiodisk))
        else:
           print(self.GREEN + n_msg)


    def rebuild_oio(self, hostname, oiodisk, ip, date, hour, mount_point, device):
        success = False
        retries = 0
        rebuitd_check = subprocess.getoutput("OIO_NS=DAILYMOTION openio cluster list rawx | grep \"{}\"| grep {}".format(hostname, oiodisk))
        print(rebuitd_check)
        if "True" in rebuitd_check:
            cmd = "OIO_NS=DAILYMOTION openio volume admin incident {}:62{} --date $(date --date='{} {}' +\"%s\")".format(ip, oiodisk, date, hour)
            self.cmd_execute(cmd)
            cmd = "oio-blob-rebuilder DAILYMOTION --volume {}:62{} --workers 10 --allow-same-rawx".format(self.ip, oiodisk)
            y_msg = "Rebuild on disk [{}] will be launched on tmux".format(oiodisk)
            n_msg = "You can launch later the rebuild on disk {} using this command : \n [{}]".format(oiodisk, cmd)
            self.launch_rebuild(y_msg, n_msg, oiodisk, "oio-blob-rebuilder DAILYMOTION --volume {}:62{} --workers 10 --allow-same-rawx".format(ip, oiodisk))
            if not os.path.ismount(self.mount_point):
                self.error_exit("Cant mount disk {} on {}".format(device, mount_point))
            while True:
                retries += 1
                try:
                    check_rawx = subprocess.getoutput ("gridinit_cmd status |grep DAILYMOTION-rawx-{}".format(oiodisk))
                    if "DOWN" or "BROKEN" not in check_rawx:
                        success = True
                        break
                except Exception as e:
                                      print("Will retry : %s" % serr)
                if retries >10:
                    self.error_exit("rawx-{} is broken or down".format(oiodisk))
                    break
        else:
            self.error_exit("Error : rawx-{} not yet disabled".format(oiodisk))

def main():
    parser = argparse.ArgumentParser(
        description='Output storcli and smartctl for a failed device',
        add_help=True
    )
    parser.add_argument('--device', type=str,
                        help='device to scan')
    parser.add_argument('--wipe', action='store_true',
                        help='wipe disk and put it back in cluster')
    parser.add_argument('--replace', action='store_true',
                        help='Change the defective disk:\
                            --replace --device /dev/sdxx\
                            --replace --enclosure xx --slot xx')
    parser.add_argument('--oio', type=str,
                        help='wipe disk and put it back in cluster')
    parser.add_argument('--pdisk', type=str,
                        help='give the pd : /cx/exx/sxx')
    args = parser.parse_args()

    if args.replace or args.wipe:
        if not args.device and not args.oio:
            sys.stderr.write('--replace and --wipe options must be used with --device or --oio.\n')
            sys.exit(1)

    if  args.device or args.oio:
        if not args.replace and not args.wipe:
            sys.stderr.write('--device and --oio options  must be used with --replace or --wipe option.\n')
            sys.exit(1)

    storcli = Storcli(args)
if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print('Interrupted')
        try:
            sys.exit(0)
        except SystemExit:
            sys.exit(0)
   
